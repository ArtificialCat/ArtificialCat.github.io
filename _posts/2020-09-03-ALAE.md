---
title:  "Adversarial Latent Auto-Encoder(ALAE) -(1)"
excerpt: "목표: Good synthesis model with disentangled latent representation"

categories:
  - AI
tags:
  - StyleGAN
  - Adversarial Loss
  - Auto-encoder
  - Generator-Encoder Map
last_modified_at: 2020-09-03T22:30:00-05:00
use_math: true
---

Generative Model을 쓸 일이 생겨서 StyleGAN, StyleGAN2를 보다가 Image를 Latent space로 투영하는 프로세스가 필요해서 보게 되었다.

# 1. Abstract
Auto-encoder는 유서 깊은 방법론이고 현 시점에서도 많이 쓰이고 있는 방법론이다. 이 방법론은 모두 알다시피 복원 생성 기반의 representation learning 방법론이다. 
결국 Auto-Encoder는 Unsupervised 방법론이기 때문에 이게 얼마나 잘 학습되었는지는 크게 2가지 관점에서 바라볼 수 있다.  
  > __Reconstruction Loss__ : 복원 생성된 instance가 input과 얼마나 유사하게 복원되었는가?  
  > __Disentanglement__  : Intermediate Layer에서 생성된 Representation이 상이한 특성에 따라 잘 분리되었는가?

이러한 관점에서 볼 때 Autoencoder 방법론이 GAN 계열 모델과 비슷한 생성 Quality를 가질지, 또는 서로 다른 특성을 가지는 instance끼리 잘 분리되는 representation을 학습할 수 있는지에 대해 아직 풀리지 않은 부분이 많이 있다.  
본 연구에서는 이 2가지 관점에 모두 욕심을 내서 풀어보려는 시도를 하였다. 저자들은 2가지의 auto-encoder 모델을 제안하는데 첫 번째로는 기본 형태를 지닌 *MLP encoder*이며, 두 번째로는 StyleGAN 모델을 기반으로 한 *StyleALAE*를 제안하였다.  
밑에서 논문에서 제시하였던 실험결과들과 함께 제안한 오토인코더가 1024x1024 image를 얼마나 잘 복원해냈는지와 Disentangle한 representation도 잘 학습해냄으로써 real image를 활용해서 face reconstruction / manipulation한 결과를 같이 살펴볼 것이다.  
  
  
# 2. Introduction
1.에서 설명했다시피 Autoencoder의 두 가지 토픽에 대한 가장 좋은 테스트베드는 역시 Vision, 그 중에서도 Face Image Reconstruction이 될 수 있다. 이는 일단 [StyleGAN](https://arxiv.org/pdf/1812.04948.pdf)과 같이 고화질의 이미지에서도 좋은 생성 성능을 보여주는 비교군이 존재하기도 때문이며, 기존에 이 2개의 토픽 중에 1개의 토픽에 초점을 맞춰서 성공적인 결과를 도출했던 연구는 여럿 있지만 jointly하게 다루기는 쉽지 않은 일이다.  

> __Generative Power__ : [IntroVAE](https://arxiv.org/pdf/1807.06358.pdf) [Autoencoding beyond pixels using a learned similarity metric](https://arxiv.org/pdf/1512.09300.pdf)  
> __Disentanglement__: [beta-VAE](https://openreview.net/pdf?id=Sy2fzU9gl) [Disentangling by factorising](https://arxiv.org/pdf/1802.05983.pdf)  
 
GAN은 고질적으로 학습시의 Model collapse나 학습 instability가 문제가 되었는데 비교적 최근 몇년간 GAN의 학습 불안정성에 대한 논의와 Training method에 대한 새로운 연구들이 많이 나왔기 때문에(ex. [Mescheder 2018](https://arxiv.org/pdf/1801.04406.pdf), [Kolter 2017](https://arxiv.org/pdf/1706.04156.pdf)) 여기서도 StyleALAE같은 모델은 Generator로 StyleGAN과 VAE를 동시에 학습시키는 model architecture를 가지게 된다.  
상세한 내용은 모델을 보면서 더 살펴보도록 하자.
ß
# 3. Model Architecture
![ALAE_Structure](/images/alae_structure.png)
*[Figure 1] ALAE의 구조, 기본 구조는 $E(x)$와 $E(G(F(z)))$를 활용한 적대적 학습이 주가 된다.*
{: .text-center }
{: .image-center }
위의 ALAE 구조에서 Notation을 살펴보면 아래와 같다.  
> **$z$** : random init latent vector  
> **$w$** : encoded representation  
> **$x$** : input  
> **$\eta$** : noise  abcd 
>  
> **$G$** : Generator  
> **$E$** : Encoder  
> **$D$** : Discriminator  
> **$F$** : Mapping Function(z to w)  

여기서는 Generator __G__ = $G \circ F$ 로 정의하고 Discriminator __D__ = $D \circ E$로 정의한다.  
위의 그림에서 F로부터 나온 G의 input과 Encoder E의 output은 (당연하게도) 동일한 w이다. F는 deterministic map이며, 반대로 Encoder와 Generator는 stochastic하게 설정하였다. 각 모듈(G, F, D, E)에서 도출되는 output은 아래와 같다.  

>=================================================  
>Generator representing distribution: $q_{G}(x | w,\eta)$  
>Encoder의 output distribution: $q_E(w) = \int_{x}q_{E}(w | x)q(x)dx$  
>Generator의 output distribution: $q(x) = \int_w\int_{\eta}q_{G}(x | w,\eta)q_{F(w)}p_{\eta}(\eta)d\eta dw$  
>=================================================  

위의 세 개의 식을 각각 살펴보기 전에 vanilla GAN의 objective function부터 리마인드해보면,  
$V(G, D) = E_{P_{data}(x)}[f(D(x))\] + E_{p(z)}[f(-D(G(z)))\]$ 로 쓸 수 있다. 
여기서 $f(t)=-log(1+exp(-t))$, softplus 함수로 정의하고 이는 concave하다.  
이제 위의 Encoder-Generator Map에서 나오는 3개의 분포식과 위에서 제시한 구조가 학습되기 위한 constraint를 하나씩 살펴볼 것이다.  
>a) $q_E(w)$부터 살펴보면 $q(x)$부분을 $p_{data}(x)$로 치환하면 real data를 input으로 가질 때 Encoder의 output distribution $q_{E,data}(w)$를 얻을 수 있다.  
$V(G,D)$의 학습은 synthetic distribution $q(x)$와 실제 데이터의 분포인 $p_{data}(x)$를 유사하게 하는 방향으로 학습된다. ($q_E(w) = q_{E, data}(w)$)  
  
>b) "_Encoder의 output과 Generator의 input이 같아야 한다_"이다. 오토인코더의 Reciprocity 성질에 관한 제약조건이다. 이를 수식으로 표현하면 $q_F(w) = q_E(w)$와 같다.  
  
이러한 방식으로 (G, E) pair의 네트워크 구조가 latent space W에 대해 auto-encodes하도록 학습시킬 수 있다.
$\Delta(p||q)$를 discrepancy of p and q라고 정의하면 a), b)의 조건을 학습하기 위해서 아래 식과 같은 optimization을 제안할 수 있다.  
  
$min_{F,G}max_{E,D}V(G \circ F, D \circ E) - (1)$
{: .text-center }  
$min_{E,G}\Delta(F||E \circ G \circ F) - (2)$
{: .text-center }  

(1)은 vanilla GAN의 그 optimization 식인 $V(G,D)$의 min-max adversarial optimization을 위 ALAE 구조에 따라 풀어서 쓴 것이다. (2)의 식에서 $F$, $E \circ G \circ F$는 각각 $q_F(w), q_E(w)$를 의미함을 다이어그램을 통해 쉽게 알 수 있다. 따라서 본 모델의 구현 코드를 보면 알겠지만 한번의 학습에서 위 (1), (2)의 loss를 계산해서 최적화하는 과정을 3개의 loss를 구해서 동시/교대로 학습시키게 된다.
  
  
## 3.1. 다른 AE 모델과의 관계
제목이 불명확하지만, 본 논문에서는 다른 AE 연구들과의 data distribution, latent distribution, reciprocity 측면에서의 공통점, 차이점에 대해서 서술하고 있으며 이 모델이 왜 이렇게 구성되었는지에 대한 약간의 이해를 더할 수 있었던 것 같아서 정리해본다.  
자세히 선행 연구를 읽고싶으면 페이퍼를 참조하는 게 좋을 것 같으며, 여기서는 간단히 아래 테이블을 통해서 언급만 하고 넘어가도록 한다.  

![AE Criteria Used Table](/images/diff_same_other_ae.png)
*Table 1. 여러 가지 기존 AE 모델의 genrator의 data 분포 학습, Encoder의 latent 분포의 학습, reciprocity의 학습이 어떻게 이루어지는지에 대해 분류하였다.*
{: .text-center}
{: .image-center}  

위 표를 보면 ALAE 모델은 Generator가 실제 Data distribution를 학습하기 위해서 Adversarial한 학습 방법을 취하고 있음을 알 수 있으며,  
Latent distribution에 대해서는 다른 방법론들은 일반적으로 어떠한 Target distribution을 정해놓고 그 target과 학습 분포의 similarity를 높인다던지, adversarial한 방식으로 학습을 하게 되는데 여기서는 따로 Target 분포를 정해놓고 그 것과 일치하도록 하는 것이 아니라 위의 (b)의 제약조건만을 줌으로써 F가 identity map이 되는 것이 아니라 학습 과정에서 자연스럽게 정해지도록 하였다고 서술하였다.  
마지막으로 Reciprocity는 $x=G(E(x))$ 또는 $w=E(G(w))$를 만족하도록 하는 성질을 의미하는데(즉 양방향의 복원 성능) 그렇다면 이 것을 데이터 공간 x에서 학습을 시킬 것인지, latent 공간 w에서 학습을 시킬 것인지는 여러 연구에 따라 차이가 있는데 여기서는 latent space에서 학습을 시켰다고 한다. 왜냐하면 l2-norm을 적용함에 있어서 데이터 공간 x보다 더 유리한 측면이 있다고 한다. ALAE의 latent space reconstruction loss에 대한 학습식은 아래와 같다.  
{: .text-left}
$\Delta(F||E \circ G \circ F) = E_{p(z)}[||F(z) - E \circ G \circ F(z)||_2^2\]$  
{: .text-center}  

첫 글인데 너무 길어져서 여기서 잠깐 끊고 다음 편은 ALAE 구조에 StyleGAN의 Generator를 도입한 StyleALAE에 대해 정리해보려고 한다.

